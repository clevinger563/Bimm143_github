---
title: "Class 8 Breast Cancer Mini Project"
author: "Christopher Levinger (A17390693)"
format: pdf
toc: true
execute:
  error: true
  echo: true
  warning: true
---

## background

This mini-project explores unsupervised learning techniques applied to the Wisconsin Breast Cancer Diagnostic Data Set, which contains measurements of human breast mass cell nuclei. The project guides the user through exploratory data analysis, performing and interpreting Principal Component Analysis (PCA) to reduce the dimensionality of the data while retaining variance, and applying hierarchical clustering with different linkage methods. It also includes an optional section on K-means clustering for comparison. The ultimate goal is to combine PCA and clustering to better separate benign and malignant cell samples, evaluating the results using metrics like sensitivity and specificity, and finally demonstrating how to predict the classification of new samples using the developed PCA model.

## Data import

Our data comes from the U. of Wisconsin Medical Center.

```{r}
read.csv("WisconsinCancer.csv", row.names=1)
```

```{r}
fna.data <- "WisconsinCancer.csv"
wisc.df <- read.csv(fna.data, row.names=1)
```
>Q1: How many observations are in the data set? 569 observations total adding both the malignant and benign samples. 
>Q2: How many of the observations have a malignant diagnosis? 
212 see result of two codes below 

```{r}
table(wisc.df$diagnosis)
```

```{r}
sum(wisc.df$diagnosis == "M")
```

>Q3: How many variables/features in the data are suffixed with _mean? 10 are suffixed with mean as seen with the codes below. 

```{r}
colnames(wisc.df)
```

```{r}
length( grep("mean", colnames(wisc.df), value=T))
```

There is a diagnosis column that is in the clinician consensus that I want to exclude from any further analysis. We will come back later and compare our results to this diagnosis. 

```{r}
diagnosis <- as.factor(wisc.df$diagnosis)
head(diagnosis)
```

Now we can remove it from the `wisc.df`

```{r}
wisc.data <- wisc.df[,-1]
```

## Clustering

Let's try a `hclust()`
```{r}
hc <- hclust( dist(wisc.data))
plot(hc)
```

We can extract clusters from this rather poor dendrogram/tree with the `cutree()` function.

```{r}
grps <- cutree(hc, k=2)
```


How many elements are in each cluster?

```{r}
table(grps)
```

We can generate a cross-table that compares our cluster `grps` vector with out `diagnosis` vector values. 

```{r}
table(diagnosis, grps)
```

## PCA: Principal Component Analysis 

The main function for PCA in base R in`prcomp()` it has a default input paramater of `scale=FALSE`.

```{r}
#prcomp()
head(mtcars)
```

We could just do PCA of this data as is, and it could be mis-leading. 

```{r}
pc <- prcomp(mtcars)
biplot(pc)
```

Let's look at the mean values of each column and the standard deviation.

```{r}
colMeans(mtcars)
```

```{r}
apply(mtcars, 2, sd)
```
We can "scale" this data before PCA to get a much better representation and analysis of all the columns. 
```{r}
mtscale <- scale(mtcars)
```

```{r}
round(colMeans(mtscale))
```

```{r}
apply(mtscale, 2, sd)
```

```{r}
pc.scale <- prcomp(mtscale)
```

We can look at the two main results figures from PCA - the "PC plot" (a.k.a score plot, ordination plot, or PC1 vs PC2 plot). The "loadings plot" how the original variables contribute to the new PCs.

## The Importance of Scaling 

A loadings plot of the unscaled PCA results
```{r}
library(ggplot2)

ggplot(pc$rotation)+
  aes(PC1, rownames(pc$rotation)) +
  geom_col()
```
Largest standard deviation will be father away from the accounted variation/line of best fit best estimated by PC1. 
```{r}
pc$rotation
```

Loadings plot of the scaled data. 
```{r}
ggplot(pc.scale$rotation)+
  aes(PC1, rownames(pc$rotation)) +
  geom_col()
```
This will pick up more columns and is a much better representation of the variation. 
PC plot of scaled PCA results 
```{r}
library(ggrepel)
ggplot(pc.scale$x)+
  aes(PC1, PC2, label=rownames(pc.scale$x))+
  geom_point() +
  geom_text_repel()
 geom_text_repel(max.overlaps = Inf)

```

>***Key point**: In general, we will set `scale=TRUE` when we do PCA. This is not the default but probably should be.

We can check the SD and mean of the different columns in `wisc.data` to see if we need to scale - hint: we do! 

### PCA of wisc.data

```{r}
wisc.pr <- prcomp(wisc.data, scale=TRUE)
```

To see how well PCA is doing here in terms of capturing the variance (or spread) in the data we can use the `summary()` function.

```{r}
summary(wisc.pr)
```

Cumulative proportion accounts for the amount of variation is accounted for by the summed PCA components of the data.

Let's make the main PC1 vs PC2 figure 

```{r}
ggplot(wisc.pr$x)+
  aes(PC1,PC2,col=diagnosis) +
  geom_point() +
  xlab("PC1 (44.3%)") +
  ylab("PC2 (19%)")
```

PCA attempts to flatten data. Points on end best represent PC1. 
Answer Questions 4-7 (Answer up to this Question 10)

>Q4: From your results, what proportion of the original variance is captured by the first principal components (PC1)? The first principal component captures about 44.27% of the variation in the entire data.

>Q5: How many principal components (PCs) are required to describe at least 70% of the original variance in the data? Three Principal components are required to capture at least 70% of the data of the variation, where the accumulation of PC1-3 accounts for just over 72% of the variation.

>Q6: How many principal components (PCs) are required to describe at least 90% of the original variance in the data? To capture at least 90% of the variation in the data, at least 7 principal components are required up to PC7.

>Q7: What stands out to you about this plot? Is it easy or difficult to understand? Why? This biplot below is very difficult to understand and does not allow us to visualize clear separation between the malignant and tumor samples across the plot. The two clusters appear heavily overlapped to the point where it appears one is nested into the other. The labeling further adds confusion to the plot and could not be used by a medical professional to clearly differentiate between the malignant and benign tumor samples. 

```{r}
biplot(wisc.pr)
```
```{r}
plot(wisc.pr$x[, 1:2], col = diagnosis, xlab = "PC1", ylab = "PC2")
```
Here, generating a plot for PC1 vs. PC2 reveals much more clarity in the separation of clusters between malignant and benign. Let's do the same comparing PC1 and PC3. 
```{r}
plot(wisc.pr$x[, c(1, 3)], 
     col = diagnosis, 
     xlab = "PC1", 
     ylab = "PC3")
```

>Q8: Generate a similar plot for principal components 1 and 3. What do you notice about these plots?
Looking at the plot comparing PC1 and PC2, it appears that we see a very clearly defined separation between the malignant and benign samples with very little overlap between the dark red and black regions. However, when looking at the plot between PC3 and PC1, it appears there is more overlap between the malignant and benign clusters, where at the interface between the two clusters, there appears many overlapping black and red circles. This phenomena can be explained by the fact that PC2 accounts for more variation in the data set than PC3, and thus when clusters are created using principal component analysis and the data is mapped onto these eigenvectors, when PC1 and PC2 are plotted, which account for the most variation in the data, there appears more defined grouping, while when PC3 is introduced, which explains less variation in the data, less defined grouping occurs, with more overlap as seen in the figure above.  

Let's try using ggplot 2 to make things more clearer. 

```{r}
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis
library(ggplot2)
ggplot(df) + 
  aes(PC1, PC2, col=diagnosis) + 
  geom_point()
```
```{r}
pr.var <- wisc.pr$sdev^2
head(pr.var)
```
This helps output the variance of each of the principal components to describe the wisc. pr data where the variance is defined as the square of the standard deviation. The head PR in this case only outputs the top 6 values from the PC components.  

```{r}
total.var <- sum(pr.var)
pve <- pr.var / total.var
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")

```
Here we can see a graph showing the relative explanation of the variance in the data captured by each of the principal components. The smaller the principal component i.e PC1, the more variance captured. 

Below is an alternative display:

```{r}
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)
```

Many different factors impact the malignant and benign separation.
## Combining Methods

We can take our PCA results and use them as a basis set for other anlysis such as clustering. 

>Q9: For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?
In this code, for the columns component we extracted out PC1, and the numeric output from this code will indicate how strongly the concave.points_mean will contribute to the PC1 component. In this case, the value outputed is -0.260853, which indicates  somewhat contribution of this value, and thus this value is the component of the loading vector i.e the amount of contribution to PC1. 

>Q10: Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?
Looking at the graph directly above, it appears that it requires at least 4 principal components up to PC4 to explain 80% of the data. 

```{r}
wisc.pr$rotation["concave.points_mean", 1]
```


## CLustering on PCA results

```{r}
wisc.pr.hclust <- hclust( dist(wisc.pr$x[,1:2]), method="ward.D2")
plot(wisc.pr.hclust)
```
We can "cut" this tree to yield our clusters (groups):

```{r}
pc.grps <- cutree(wisc.pr.hclust, k=2)
table(pc.grps)
```
How do my cluster groups compare to the expert diagnosis

```{r}
table(diagnosis, pc.grps)
```
```{r}
table(diagnosis)
```

```{r}
data.scaled <- scale(wisc.data)
```

```{r}
data.dist <- dist(data.scaled)
```

```{r}
wisc.hclust <- hclust(data.dist, method="complete")
```

```{r}
plot(wisc.hclust)
abline(h=19,col="red",lty=2)
cutree(wisc.hclust, k=4)
```

> Q11: Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters? Referncing the lab handout sheet and the figure above, when the tree was cut at around a height of 19, it appears that 4 major clusters appear with multiple data points, consistent with the two sheets. 

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
```




```{r}
table(wisc.hclust.clusters, diagnosis)
```
Here, after dividing into 4 clusters we can see clusters 1 and 3 have the most benign or malignant cases while the other two have very little in both. 
> Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?
Yes we can find a better cluster versus diagnosis match by dividing into 5 clusters, as seen below where for each cluster there is a clear majority of either malignant or benign. Looking at clusters 1 and 3, these show majority malignant and benign, respectively, exactly identical to the numbers seen in cluster 4. However, the other few cases with cluster 2 and 4 are better spread out among the additional cluster, to the point where they are either all benign or all malignant, as seen in rows 2, 4 and 5 below. This makes a great separation of the malignant and benign samples among the clusters better than when k=4. When k was set to 3 or 2, it was clearly seen that there was one row where there was a large amount of both benign and malignant, ensuring not great separation. k=6 was also a good separation and is debatable with the k=5 separation, the only difference being the slighltly less benign in row 3 and the 12:1 B:M seen in row 5, which is not as good as the complete separation we saw in those other rows for k=5. As k increased even more, the malignant samples began to spread over multiple rows more and more evenly, which was not as great of a separation as k=5.  

```{r}
wisc.hclust.clusterss <- cutree(wisc.hclust, k=5)
```

```{r}
table(wisc.hclust.clusterss, diagnosis)
```

```{r}
wisc.hclustt <- hclust(data.dist, method="single")
```

```{r}
plot(wisc.hclustt)
```

```{r}
wisc.hclusttt <- hclust(data.dist, method="average")
```

```{r}
plot(wisc.hclusttt)
```

```{r}
wisc.hclustttt <- hclust(data.dist, method="ward.D2")
```
```{r}
plot(wisc.hclustttt)
```
>Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.
From all the results that are plotted above as dendograms, the one that gives me my favorite results is the ward D.2 methods, which involves calculation of distance based upon the centroid of each clusters as the clusters continually get bigger using the bottom-up hierarchy method. This is because after looking at all the plots above, the ward. d2 graphs gives the most clear separation, between two clusters, with a crossbar with a very high height connecting them, indicating 2 very nested clusters that have a very large separation distance between them. This separation gives me the most hope that we will be able to extract out 2 distinct clusters, with one being the malignant and the other being the benign group. 

## K means clustering
```{r}
wisc.km <- kmeans(data.scaled, centers=2, nstart=20)
```

```{r}
table(wisc.km$cluster, diagnosis)
```
> Q14. How well does k-means separate the two diagnoses? How does it compare to your hclust results?
For the separation into 2 clusters, the k means method did better than the bottom up hierarchy method. Looking at the separation in the 2 clusters, for the first row it appears that the majority of the samples are benign, with 356 versus 82, and although this separation could be better the separation is ok. Looking at the hierarchy method when the dendogram was divided into 2 clusters on the complete method, two clusters appeared one with 357 benign and the other with 210 malignant, which is a much worse separation and difficult to isolate this one group as malignant or benign. Looking at the second row for the k means method, it appears that 130 were assigned into the malignant which is a massive majority over the 1 benign indicating gerat separation again for the k means method. 

## Combining Methods


```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```
```{r}
table(grps, diagnosis)
```
```{r}
plot(wisc.pr$x[,1:2], col=grps)
```

```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
```


```{r}
g <- as.factor(grps)
levels(g)
```

```{r}
g <- relevel(g,2)
levels(g)
```

```{r}
plot(wisc.pr$x[,1:2], col=g)
```

```{r}
data.dist <- dist(wisc.pr$x[, 1:7])
wisc.pr.hclust <- hclust(data.dist, method = "ward.D2")
```

```{r}
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
```

```{r}
table(wisc.pr.hclust.clusters, diagnosis)
```

```{r}
wwisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=4)
```

```{r}
table(wwisc.pr.hclust.clusters, diagnosis)
```

>Q15: How well does the newly created model with four clusters separate out the two diagnosis?
Looking at the above model, where the data was divided into 4 clusters, it does a decent job of separating out the diagnosis, with row 3 being the worst of the separation. Row 1 does a perfect job of isolating all the malignant cases, while row 2 also does a great job of separting out the malignant cases. Row 3 does the worst job of separation, where there are only 30 more malignant compraed to benign. Row 4 also does a decent job of separation with the majority of the diagnosis being benign compared to only 24 malignant. This clustering method for 2 clusters as seen in the code just above the previous one also does a decent job at isolating the diagnosis with 188 being of the malignant with only 28 benign in the first row, and for the second row grabbing the opposite with 329 benign and 24 malignant. 

```{r}
table(wisc.km$cluster, diagnosis)
```

```{r}
table(wisc.hclust.clusters, diagnosis)
```
```{r}
wwwisc.hclust.clusters <- cutree(wisc.hclust, k=2)
```

```{r}
table(wwwisc.hclust.clusters, diagnosis)
```


>Q16: How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.
Looking at the two methods, which we were instructed to do the k-clustering into 2 clusters and the hierarchy method to cut the dendogram into 4 major clusters, the separation is ok but not nearly perfect to where we can definitively have two groups with malignant and benign. Looking at the k-clustering method for two clusters, the first row has 356 for benign and 82 for malignant, which still shows a pretty good shot of finding a malignant sample in this group, and is thus not a great separation. It did decenetly separate the malignant group though, with only 1 benign present. For 4 clusters, the hierarchal method did not do a perfect job either with 165 in the malignant and 12 in the benign and for row 3 with 40 in malignant and 343 with benign. This did an ok separation, but there is still some overlap that could lead to false  negative malignant samples if a physician were to use these samples and thus would not to be to standard for medical practice. Comparing to the 2 cluster separation in the hierarchal method, it did a horrible job of separation. Looking at the first row, there is only slightly more benign than malignant with the second row having almost nothing. These results, when directly compared to the kclustering method when there are 2 clusters, did a much worse job and is not useful data in any sense. 

>Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?
Looking at the k means method where 2 clusters were used, the maximum number of malignant in a cluster was 130 with therefore 82 false negatives, yielding a sensitivy percentage of approximately 61. Looking at the specificity percentage, there 356 cases as the maximum number of benign in one cluster with 1 false negative in the second cluster yielding a specificity percentage of 99.72%.
Looking at the hierarchal method where 4 clustesr were used, the senstivity percentage was calculated looking ath the maximum number of malignant cases in one cluster which was 165, leaving 47 false negativves. This yielded a percentage of 77.83%. FOr the specificity percentage, the maximum number of benign in a column was 343 with 14 false negatives leading to a specificity percentage of 96.07%. 
This indicates that the the heirarchal method yielding a better sensitivity, and the k means method had a better specificity. 
They did really badly. We do much better after PCA - the new PCA variables (what we call a basis set) give us much better separation of M and B.

## 7. Prediction
We can use our PCA model for the analysis of new "unseen"' data. In this case from U. Mich.

```{r}
h <- cutree(wisc.pr.hclust, k = 2)
```



```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```
```{r}
plot(wisc.pr$x[,1:2], col=h)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```


>Q18: Which of these new patients should we prioritize for follow-up based on the results? 
We should prioritize patient 2, which in this case is seen in black. This is because after running the Prinicipal Component analysis and drawing a line of best fit for the datap points, constituting PC1, and then looking at the second most variation, being PC2, and aftter creating new axes based on these principal components, we see two distinct clusters emerge, where the samples of patient 2 being malignant, clearly differentiate from the first cluster and should be prioritized. 